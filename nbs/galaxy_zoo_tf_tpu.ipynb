{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Galaxy Zoo challenge with Tensorflow and TPUs\n",
    "\n",
    "[Galaxy Zoo](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge) was a machine learning competition on Kaggle wherein competitors had to build a model that could predict galaxy morphology features based on its `JPG` image. In a [previous notebook](https://colab.research.google.com/drive/1i6ghXgyQPcyLn5Q9-c7QbIsMEpY4vqQQ), we used the `fastai` library to build a `ResNet18` model for this task. Due to the number of training images and the complexity of the model, we could not fit it for all the images. We instead had to rely on a small sample of images (about 10%) in order to train a model in reasonable amount of time.\n",
    "\n",
    "With this notebook, the aim is to see if a combination of the TensorFlow package and *Tensor Processing Units* (TPUs) (specialised hardware built for machine learning by Google) can help us train `ResNet18` or even deeper models on the entire training dataset in a reasonable amount of time.\n",
    "\n",
    "The `fastai` package is built on top of another deep learning package called *PyTorch*. Thus, with this notebook, we will be exploring some TensorFlow syntax (Keras to be specific) and understanding how to configure a notebook to run on TPUs.\n",
    "\n",
    "## Step 0: Prerequisites\n",
    "Let us begin with by mounting our Google Drive (where the data is stored) and loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files, drive\n",
    "import sys\n",
    "\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/Colab Notebooks/fastai_2022/data/galaxy-zoo-the-galaxy-challenge\"\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now do a quick check to ensure that we are able to access the contents of this directory in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data\n",
    "\n",
    "We know that the training images are in the directory `images_training_rev1`. Let us begin by creating a `tf.data.Dataset` object that can access all the training images. \n",
    "\n",
    "`tf.data.Dataset` is an API that allows us to write input data pipelines effectively. It provides a convenient way for multiple functions/operations like:\n",
    "- Create a data source from input data.\n",
    "- Apply transformations to preprocess the data.\n",
    "- Iterate over the data to process its elements.\n",
    "\n",
    "This API can handle data of multiple types like images, text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir: Path = Path(root_dir)\n",
    "training_img_dir: Path = Path(root_dir/\"images_training_rev1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds: Dataset = tf.data.Dataset.list_files(f\"{str(training_img_dir)}/*.jpg\", shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the images. By doing so, we can evaluate the performance of our model as there should not be a significant discrepancy in its results with different shuffled images. With `reshuffle_each_iteration` set to `False`, we prevent shuffling with every epoch of our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count: int = len(list(training_img_dir.glob(\"*.jpg\")))\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we list the paths of first five images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the outputs for these images are available as columns in `training_solutions_rev1.csv`. Let us first load and peek at this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_outputs: pd.DataFrame = pd.read_csv(root_dir/\"training_solutions_rev1.csv\")\n",
    "training_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the `GalaxyID` column match the filenames. So, let us modify these values to full paths for the corresponding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_outputs = (training_outputs.assign(GalaxyImageFile=lambda x: [f\"{str(training_img_dir)}/{id}.jpg\" for id in x['GalaxyID'].to_list()])\n",
    "                    .drop(\"GalaxyID\", axis=1))\n",
    "training_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_factor: float = 0.2\n",
    "x_train: list\n",
    "y_train: np.ndarray\n",
    "x_valid: list\n",
    "y_valid: np.ndarray\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    training_outputs.loc[:, \"GalaxyImageFile\"].to_list(), \n",
    "    training_outputs.drop(\"GalaxyImageFile\", axis=1).values, \n",
    "    test_size=val_factor, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs: int = int(y_train.shape[1])\n",
    "num_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `x_{train|test}` holds Galaxy IDs that correspond to image file names and `y_{train|test}` holds outputs for each image. Let us now create tensors for the IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_ds: Dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "valid_id_ds: Dataset = tf.data.Dataset.from_tensor_slices(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a function to load the images. As TensorFlow's `ResNet50` model was trained of images of size *224 x 224 x 3`, we modify the image height and width accordingly. \n",
    "\n",
    "Along with it, let us define the desired dimensions of the image to be used for training the model and the number of images to process in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 32\n",
    "img_height: int = 224  # 180\n",
    "img_width: int = 224  # 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img: tf.Tensor) -> tf.Tensor:\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size. The output is a 3-D float Tensor\n",
    "    # of shape `[new_height, new_width, channels]`.\n",
    "    return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(fp: tf.Tensor) -> tf.Tensor:\n",
    "    file_contents: tf.Tensor = tf.io.read_file(fp)\n",
    "    img: tf.Tensor = decode_img(file_contents)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_img_ds: Dataset = train_id_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "valid_img_ds: Dataset = valid_id_ds.map(load_image, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create tensors of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_ds: Dataset = tf.data.Dataset.from_tensor_slices(tf.cast(y_train, tf.float32))\n",
    "valid_output_ds: Dataset = tf.data.Dataset.from_tensor_slices(tf.cast(y_valid, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us combine the images and outputs into `(image, outputs)` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds: Dataset = tf.data.Dataset.zip((train_img_ds, train_output_ds))\n",
    "valid_ds: Dataset = tf.data.Dataset.zip((valid_img_ds, valid_output_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print some information about one of the input-output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, output in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: We tried to load the data using the code structure and syntax provided in the [Tensorflow tutorial](https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control) but as the value passed by `map()` in each iteration is a *symbolic tensor*, we could not use it fetch the outputs from a dataframe directly.\n",
    "\n",
    "Next, we configure the dataset for improved performance i.e.:\n",
    "- Ensure it is well-shuffled\n",
    "- Make it batched\n",
    "- Ensure that batches are available as soon as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds: Dataset) -> Dataset:\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final check, let us see one of the training images with its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(1):\n",
    "    print(f\"Output: {label_batch[i].numpy().tolist()}\")\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train model\n",
    "\n",
    "Having loaded the data, let us now define a neural network and train it for the data. In our [fastai notebook](https://colab.research.google.com/drive/1i6ghXgyQPcyLn5Q9-c7QbIsMEpY4vqQQ), we used the `ResNet18` model but the same model is not easily available in TensorFlow. Instead, we will use the `ResNet50` model. Both are neural networks consisting of *residual units* in the hidden layers. The main difference between them is that `ResNet18` consists of 18 layers while `ResNet50` consists of 50 layers.\n",
    "\n",
    "TensorFlow provides a service called [TensorFlow Hub](https://tfhub.dev/) which allows us to easily download models pretrained on a larger dataset. By downloading the *feature vector* version of model (also called the *headless version*), we get the entire pretrained except for the output layer. We can thus use this layer and attach an output layer and/or other layers in between to train our model.\n",
    "\n",
    "To fetch the feature vector, we first search for the required model on TensorFlow Hub and then copy the URL provided for downloading the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50_url: str = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
    "\n",
    "feature_extractor_model: str = resnet_50_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we wrap the feature extractor in a Keras layer using `hub.KerasLayer()`. While doing so, we specify the dimensions of our images and set the `trainable` attribute to `False` to prevent model training from affecting features in this pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer: hub.KerasLayer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get a batch of training images from our dataset. A batch consists of 32 images of dimensions *224 x 224 x 3*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch: tf.Tensor\n",
    "labels_batch: tf.Tensor\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now pass this batch through the feature extractor layer to understand the structure of its output. We see that, for each image, the output of the layer consists of 2048 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch: tf.Tensor = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that each of our images has a list of 37 real values as outputs. So, let us create a simple network by attaching a fully-connected layer of 37 hidden units to the feature extractor layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: Sequential = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, let us generate predictions from it. The predictions themselves will be meaningless but we can ensure that our code from data loading to model prediction is working fine. Once again, we predict on a batch of images and see that the result is a `Tensor` with 37 outputs for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_test: tf.Tensor = model(image_batch)\n",
    "predictions_to_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we initiate training, let us first compile our model. We will use the *Adam* optimiser, *Mean Absolute Error* as the loss function, and the *Root Mean Squared Error* to use as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now define a TensorBoard callback to automatically capture loss and metric values during model training and show them in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/fit/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1)  # Enable histogram computation for every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us fit the model by specifying the training and validation datasets and fitting the model for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS: int = 10\n",
    "\n",
    "history: dict = model.fit(train_ds,\n",
    "                          validation_data=val_ds,\n",
    "                          epochs=NUM_EPOCHS,\n",
    "                          callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Load and preprocess images: Using tf.data for finer control](https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control)\n",
    "- [Get string value from a tensor in `Dataset.map()`](https://stackoverflow.com/questions/56122670/how-to-get-string-value-out-of-tf-tensor-which-dtype-is-string)\n",
    "- [galaxy_zoo_Xception](https://www.kaggle.com/code/hironobukawaguchi/galaxy-zoo-xception)\n",
    "- [Transfer learning with TensorFlow Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub#download_the_headless_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
