{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Galaxy Zoo challenge with Tensorflow and TPUs\n",
    "\n",
    "[Galaxy Zoo](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge) was a machine learning competition on Kaggle wherein competitors had to build a model that could predict galaxy morphology features based on its `JPG` image. In a [previous notebook](https://colab.research.google.com/drive/1i6ghXgyQPcyLn5Q9-c7QbIsMEpY4vqQQ), we used the `fastai` library to build a `ResNet18` model for this task. Due to the number of training images and the complexity of the model, we could not fit it for all the images. We instead had to rely on a small sample of images (about 10%) in order to train a model in reasonable amount of time.\n",
    "\n",
    "With this notebook, the aim is to see if a combination of the TensorFlow package and *Tensor Processing Units* (TPUs) (specialised hardware built for machine learning by Google) can help us train `ResNet18` or even deeper models on the entire training dataset in a reasonable amount of time.\n",
    "\n",
    "The `fastai` package is built on top of another deep learning package called *PyTorch*. Thus, with this notebook, we will be exploring some TensorFlow syntax (Keras to be specific) and understanding how to configure a notebook to run on TPUs.\n",
    "\n",
    "## Step 0: Prerequisites\n",
    "Let us begin with by mounting our Google Drive (where the data is stored) and loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files, drive\n",
    "import sys\n",
    "\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/Colab Notebooks/fastai_2022/data/galaxy-zoo-the-galaxy-challenge\"\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now do a quick check to ensure that we are able to access the contents of this directory in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data\n",
    "\n",
    "We know that the training images are in the directory `images_training_rev1`. Let us begin by creating a `tf.data.Dataset` object that can access all the training images. \n",
    "\n",
    "`tf.data.Dataset` is an API that allows us to write input data pipelines effectively. It provides a convenient way for multiple functions/operations like:\n",
    "- Create a data source from input data.\n",
    "- Apply transformations to preprocess the data.\n",
    "- Iterate over the data to process its elements.\n",
    "\n",
    "This API can handle data of multiple types like images, text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir: Path = Path(root_dir)\n",
    "training_img_dir: Path = Path(root_dir/\"images_training_rev1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds: Dataset = tf.data.Dataset.list_files(f\"{str(training_img_dir)}/*.jpg\", shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the images. By doing so, we can evaluate the performance of our model as there should not be a significant discrepancy in its results with different shuffled images. With `reshuffle_each_iteration` set to `False`, we prevent shuffling with every epoch of our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count: int = len(list(training_img_dir.glob(\"*.jpg\")))\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we list the paths of first five images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the training images into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size: int = int(image_count * val_factor)\n",
    "train_ds: Dataset = list_ds.skip(val_size)\n",
    "valid_ds: Dataset = list_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in train_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the outputs for these images are available as columns in `training_solutions_rev1.csv`. Let us first load and peek at this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_outputs: pd.DataFrame = pd.read_csv(root_dir/\"training_solutions_rev1.csv\")\n",
    "training_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the `GalaxyID` column match the filenames. So, let us modify these values to full paths for the corresponding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_outputs = (training_outputs.assign(GalaxyImageFile=lambda x: [f\"{str(training_img_dir)}/{id}.jpg\" for id in x['GalaxyID'].to_list()])\n",
    "                    .drop(\"GalaxyID\", axis=1))\n",
    "training_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_factor: float = 0.2\n",
    "x_train: list\n",
    "y_train: np.ndarray\n",
    "x_valid: list\n",
    "y_valid: np.ndarray\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    training_outputs.loc[:, \"GalaxyImageFile\"].to_list(), \n",
    "    training_outputs.drop(\"GalaxyImageFile\", axis=1).values, \n",
    "    test_size=val_factor, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `x_{train|test}` holds Galaxy IDs that correspond to image file names and `y_{train|test}` holds outputs for each image. Let us now create tensors for the IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_ds: Dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "valid_id_ds: Dataset = tf.data.Dataset.from_tensor_slices(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a function to load the images. Along with it, let us define the desired dimensions of the image to be used for training the model and the number of images to process in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 32\n",
    "img_height: int = 180\n",
    "img_width: int = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img: tf.Tensor) -> tf.Tensor:\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size. The output is a 3-D float Tensor\n",
    "    # of shape `[new_height, new_width, channels]`.\n",
    "    return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(fp: tf.Tensor) -> tf.Tensor:\n",
    "    file_contents: tf.Tensor = tf.io.read_file(fp)\n",
    "    img: tf.Tensor = decode_img(file_contents)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_img_ds: Dataset = train_id_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "valid_img_ds: Dataset = valid_id_ds.map(load_image, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create tensors of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_ds: Dataset = tf.data.Dataset.from_tensor_slices(tf.cast(y_train, tf.float32))\n",
    "valid_output_ds: Dataset = tf.data.Dataset.from_tensor_slices(tf.cast(y_valid, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us combine the images and outputs into `(image, outputs)` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds: Dataset = tf.data.Dataset.zip((train_img_ds, train_output_ds))\n",
    "valid_ds: Dataset = tf.data.Dataset.zip((valid_img_ds, valid_output_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print some information about one of the input-output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, output in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: We tried to load the data using the code structure and syntax provided in the [Tensorflow tutorial](https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control) but as the value passed by `map()` in each iteration is a *symbolic tensor*, we could not use it fetch the outputs from a dataframe directly.\n",
    "\n",
    "Next, we configure the dataset for improved performance i.e.:\n",
    "- Ensure it is well-shuffled\n",
    "- Make it batched\n",
    "- Ensure that batches are available as soon as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds: Dataset) -> Dataset:\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final check, let us see one of the training images with its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(1):\n",
    "    print(f\"Output: {label_batch[i].numpy().tolist()}\")\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Load and preprocess images: Using tf.data for finer control](https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control)\n",
    "- [Get string value from a tensor in `Dataset.map()`](https://stackoverflow.com/questions/56122670/how-to-get-string-value-out-of-tf-tensor-which-dtype-is-string)\n",
    "- [galaxy_zoo_Xception](https://www.kaggle.com/code/hironobukawaguchi/galaxy-zoo-xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
